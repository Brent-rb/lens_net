generate_data.py
================
Dependencies:
-------------
    stiff: Converts .FITS to .TIF

Usage:
------
    -o specifies output folder
    -n amount of images to generate

Example:
--------
    Generates 100 training images in the folder ./training_data/ 
    This will also generate a data file ./training_data/data.json which links images to their parameters.
    =====================================================================================================
    python3 generate_data.py -o training_data/ -n 100       


lens_net.py
===========
Dependencies:
-------------
    Unknown

Usage:
------
    -t Training flag, using this flag will train the network model on the given input
    -e Evaluate flag, using this flag will evaluate the network model on the given input
    -p Prediction flag, using this flag will use the network model to make a prediction about the input. Cannot be combined with -t or -e
    -m Model, specify the model filename. This may include a directory e.g. models/model1, the program will add the correct extensions by itself.
    -i Input, specify the input file. For training and evaluating this must be a data.json file generated by generate_data. For predictions this must be a data.json file or an image file
    -r Remove, using this flag will remove the model from disk and creates a new one with the same name.

Important to know:
------------------
    The model name is used as an identifier for normaliztion. If normalization is used when training, the program will use the model name as identifier to store 
    the normalization parameters. This is neccessary to transform the normalized output to actual output when predicting. 
    If the model includes a directory e.g. models/model1 the directory will be stripped. In this case the model identifier would be "model1"

Examples:
---------
    Training and evaluating model1 with the training data specified in ./training_data/data.json. 
    If model1 exists on disk, the model will be loaded. If not, a new model will be created and stored afterwards.
    ==============================================================================================================
    python3 lens_net.py -te -i training_data/data.json -m models/model1     
    
    Using model1 to make a prediction about gal_0.tif
    =================================================
    python3 lens_net.py -p -i training_data/gal_0.tif -m models/model1

    Using model1 to make a prediction about all the images mentioned in data.json
    =============================================================================
    python3 lens_net.py -p -i prediction_data/data.json -m models/model1

    Deleting model1 on disk, create and train a new model that will be saved as model1 on disk
    ==========================================================================================
    python3 lens_net.py -tr -i training_data/data.json -m models/model1

    Evaluate model2
    ===============
    python3 lens_net.py -e -i training_data/data.json -m models/model2

Config file
===========
    The config file config.json is automatically generated if it does not exists on first run.
    It can then be modified to make changes to the neural network.
    Settings under "default" change the behavior of the neural network and/or training.
    Settings unders other keys are automatically generated by the program and should not be manually edited.

    - batch_size:       Specifies the amount of images that are in 1 mini-batch (Lower is better, bigger is faster)
    - classes:          Specifies the classes available in the output layer. These are the keys of parameters stored in data.json
                        For example ["g1", "g2"] will train the neural network to guess these 2 parameters.
    - epochs:           Specifies the amount of generations/epochs to train
    - image_height:     Specifies the height of the input images
    - image_width:      Specifies the width of the input images
    - learning_rate:    Specifies the learning rate of the neural network optimizer. Higher will learn faster but is more likely to overshoot. Use lower values when the loss value is small.
    - loss_function:    Specifies the loss function that will be used to judge performance. This function will be used to calculate a loss value. The optimizer will try to minimize this loss value.
    - metrics:          Specifies the metrics that will be displayed while training the network. Does not change behavior of the network. It is only used to give you an indication of the performance of the network.
    - mode:             Specifies the image read mode. Can be "grayscale" or "rgb"
    - normalize_output: Specifies wether or not the output layer data should be normalized. If yes, the validation data will be normalized.
    - random_state:     Specifies the random seed to split the training data into evaluation data and test data.
    - test_ratio:       Specifies the ratio of evaluation data vs training data. A ratio of 0.25 means that 25% of the training data will be used as evaluation data.



Quickstart:
===========
    1. Generate training data (1000 images) with generate_data.py
    -------------------------------------------------------------
    python3 generate_data.py -o data/train/ -n 1000 

    2. Generate prediction data (100 images) with generate_data.py
    --------------------------------------------------------------
    python3 generate_data.py -o data/predict/ -n 100

    3. Train and evaluate a newly created network
    ---------------------------------------------
    python3 lens_net.py -te -i data/train/data.json -m models/model1

    4. Get a nice cup of coffee while training
    ------------------------------------------

    5. Make a prediction about a single image
    -----------------------------------------
    python3 lens_net.py -p -i data/predict/gal_0.tif -m models/model1

    5.1. Or make a prediction about a list of images and compare the results
    ------------------------------------------------------------------------
    python3 lens_net.py -p -i data/predict/data.json -m models/model1