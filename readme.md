# LensNet

Trying to determine the shearing parameters caused by gravity to reverse weak lensing by using deep neural networks.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

```
python3, pip3
```

I also, strongly recommend setting up a `virtualenv` for this project to prevent version conflicts.

### Installing

First we need to install Keras as this is the framework the whole project is based off of. 
You can follow along with their installtion guide [here](https://keras.io/#installation).
If you want to train networks on your GPU I recommend also following their guide on installing Cuda and cuDNN.

Secondly, the software we use to generate data is called [GalSim](https://github.com/GalSim-developers/GalSim). 
You can follow along with their installation instructions on their github page. 
I had some issues with installing the GalSim python package because of the `eigency` dependency. 
A possible solution I found said to install the `cython` package, however my issue still persisted after installing `cython`.
When I tried installing `eigency` later, I no longer had issues so I do not know if `cython` is required or not.

After installing these 2 dependencies you should install all the required python packages mentioned in [requirements.txt](requirements.txt)
```
pip3 install -r requirements.txt
```

GalSim uses the `.fits` format as output. Because I am unfamiliar with this file format and not much software is written for it, I decided to convert every image to `.tif`. For this conversion the package `stiff` is required.
```
Arch:
yay stiff

Ubuntu:
apt install stiff
```

Once that is finished, you can test if GalSim works by generating a bit of data with this command:
```
python3 generate_data.py -o training_data/ -n 10
```
This will generate 10 training images in ./training_data. 

Afterwards, you can test if Keras/Tensorflow is correctly set up by running this command:
```
python3 lens_net.py -te -i training_data/data.json -m models/test
```

If no errors are present, everything should be set-up correctly!

### Generating training data

The sole purpose of the [generate_data.py](generate_data.py) script is to generate training data.
The script has 3 parameters:
* `-n [number]` Specifies how many images to generate.
* `-o [output_folder]` Specifies the output folder.
* `--noise` Adds noise to the training images.

By default the script will generate PSF with random shears (e1, e2) between [-0.04, 0.04] and galaxies with gravitational shears between [-0.4, 0.4]. These values are hard coded within the script itself but can be freely edited. These values were chosen arbitrarely and are by no means the best parameters.

The script will generate n amount of galaxies and psf's. These will be stored in the specified folder with names gal_x.fits, gal_x.tif, psf_x,fits, psf_x.tif. After all galaxies and psf's are generated, a data.json file will also be generated. This file is a json array which links every image with their randomly generated parameters. An entry in this array looks like this:
```
{
    "galaxy": "gal_158.tif",
    "psf": "psf_158.tif",
    "e1": 0.03816014137828091,
    "e2": -0.012365468694283902,
    "g1": -0.31651577551804166,
    "g2": -0.32024518396124746
}
```
These will later be used as input for training and evaluating our neural networks and can be used to make a prediction with our neural networks.

### Creating and training neural networks

Everything that has to do with neural networks can be done with the [lens_net.py](lens_net.py) script. 
This script has the following parameters:
* `-t --train` This is the training flag, use this flag if you want to train the specified model. Can be combined with `-e`.
* `-e --evaluate` This is the evaluation flag, use this flag if you want to evaluate the specified model. Can be combined with `-t`.
* `-p --predict` This is the prediction flag, use this flag if you want to make a prediction using the specified model. Can not be combined with `-te`.
* `-m --model [model]` Specifies the filepath where the model is stored/will be stored. This must be a filename without extensions, these will be generated by the script itself.
* `-i --input [input]` Specifies the input file. Must be a `data.json` file for training and evaluating. Can be a `data.json` file or image file for making predictions.
* `-r --remove` This is the remove flag, use this flag if you want to delete the stored neural network model and create a new one.

The model name will also be used as unique identifier for normalization. When normalization is used, predictions from the neural network will have a value between [0, 1], to convert these values back to actual parameters we need to undo the normalization. 

During the preperation of the training data, the values used for normalization will be stored in the config file in so they can be used during predictions. Because of this, if you decide to rename your model you also need to edit the config.json file. 

If the model parameter includes a directory, for example: models/model, this directory will be stripped. In this case, the models name would be "model". Because of this, even if your models are stored in different directories, they should have an unique name. The benefit of this approach is that you are free to move models however you see fit without having to edit the config file. 

When using the `-p` flag, you have a choice of input. If you use a `data.json` as input, a prediction will be made about every entry in the array and the result will be compared with the actual answer. If you choose an image as input there will be a prediction without comparison.

### The config file
The config file config.json is automatically generated if it does not exists on first run. It can then be modified to make changes to the neural network. Settings under "default" change the behavior of the neural network and/or training. Settings unders other keys are automatically generated by the program and should not be manually edited.

* `batch_size` Specifies the amount of images that are in 1 mini-batch (Lower is better, bigger is faster)
* `classes` Specifies the classes available in the output layer. These are the keys of parameters stored in data.json
For example ["g1", "g2"] will train the neural network to guess these 2 parameters.
* `epochs` Specifies the amount of generations/epochs to train
* `image_height` Specifies the height of the input images
* `image_width` Specifies the width of the input images
* `learning_rate` Specifies the learning rate of the neural network optimizer. Higher will learn faster but is more likely to overshoot. Use lower values when the loss value is small.
* `loss_function` Specifies the loss function that will be used to judge performance. This function will be used to calculate a loss value. The optimizer will try to minimize this loss value.
* `metrics` Specifies the metrics that will be displayed while training the network. Does not change behavior of the network. It is only used to give you an indication of the performance of the network.
* `mode` Specifies the image read mode. Can be "grayscale" or "rgb"
* `normalize_output` Specifies wether or not the output layer data should be normalized. If yes, the validation data will be normalized.
* `random_state` Specifies the random seed to split the training data into evaluation data and test data.
* `test_ratio` Specifies the ratio of evaluation data vs training data. A ratio of 0.25 means that 25% of the training data will be used as evaluation data.

### Examples
Training and evaluating model1 with the training data specified in ./training_data/data.json. 
If model1 exists on disk, the model will be loaded. If not, a new model will be created and stored afterwards.
```
python3 lens_net.py -te -i training_data/data.json -m models/model1
```    

Using model1 to make a prediction about gal_0.tif
```
python3 lens_net.py -p -i training_data/gal_0.tif -m models/model1
```

Using model1 to make a prediction about all the images mentioned in data.json
```
python3 lens_net.py -p -i prediction_data/data.json -m models/model1
```

Deleting model1 on disk, create and train a new model that will be saved as model1 on disk
```
python3 lens_net.py -tr -i training_data/data.json -m models/model1
```

Evaluate model2
```
python3 lens_net.py -e -i training_data/data.json -m models/model2
```

### Quickstart
1. Generate training data (1000 images) with generate_data.py
```
python3 generate_data.py -o data/train/ -n 1000
```

2. Generate prediction data (100 images) with generate_data.py
```
python3 generate_data.py -o data/predict/ -n 100
```

3. Train and evaluate a newly created network
```
python3 lens_net.py -te -i data/train/data.json -m models/model1
```

4. Get a nice cup of coffee while training

5. Make a prediction about a single image
```
python3 lens_net.py -p -i data/predict/gal_0.tif -m models/model1
```

6. Or make a prediction about a list of images and compare the results
```
python3 lens_net.py -p -i data/predict/data.json -m models/model1
```

## Authors

* **Brent Berghmans** 

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details
